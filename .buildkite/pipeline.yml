steps:
  - label: "Run Weight Loading Multiple GPU Test"
    agents:
        queue: vllm-image
    soft_fail: false
    retry:
      automatic:
        - exit_status: -1  # Agent was lost
          limit: 1
        - exit_status: -10  # Agent was lost
          limit: 1
    env:
      VLLM_USAGE_SOURCE: "ci-test"
    commands:
      - (command nvidia-smi || true)
      - export VLLM_LOGGING_LEVEL=DEBUG
      - export VLLM_ALLOW_DEPRECATED_BEAM_SEARCH=1
      - cd /vllm-workspace/tests
      - bash weight_loading/run_model_weight_loading_test.sh -c weight_loading/models.txt
    plugins:
      - kubernetes:
          podSpec:
            priorityClassName: ci
            containers:
            - image: public.ecr.aws/q9t5s3a7/vllm-ci-postmerge-repo:c92acb9693c0504d7dabed2a0251b9f5d4ddaebb
              resources:
                requests:
                  nvidia.com/gpu: 2
                limits:
                  nvidia.com/gpu: 2
                env:
                - name: VLLM_USAGE_SOURCE
                  value: ci-test
            nodeSelector:
              kubernetes.io/hostname: "wrk-4"
            volumes:
            - name: devshm
              emptyDir:
                medium: Memory
            - name: hf-cache
              hostPath:
                path: /root/.cache/huggionface
                type: Directory
